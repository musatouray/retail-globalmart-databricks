## Global Mart Retail Analytics Platform

An end-to-end **Data Lakehouse analytics project** built on Databricks, following the **Medallion Architecture (Bronze, Silver, Gold)**.  
The project demonstrates real-world data engineering practices including incremental data loading, dimensional modeling, and analytics-ready data design using **Spark, PySpark, SQL, Delta Lake, and Unity Catalog**.

Designed as both a **learning project and a portfolio-grade implementation** aligned with production data engineering patterns.

---

### ğŸ—ï¸ Architecture
- Databricks with Unity Catalog for governance
- Medallion Architecture (Bronze / Silver / Gold)
- Kimball-style Star Schema (facts and dimensions)
- Power BI for analytics and reporting

---

### ğŸ“ˆ Data Flow
Raw CSV â†’ Bronze â†’ Silver â†’ Gold â†’ Star Schema â†’ Power BI

---

### ğŸ¥‰ Bronze Layer
- Raw data ingestion from CSV files
- Minimal transformations
- Schema inference and storage as Delta tables (`orders_bronze`)

---

### ğŸ¥ˆ Silver Layer
- Data cleansing and standardization
- Type casting, validation, and basic data quality rules
- Schema evolution handled using Delta Lake
- Stored as Delta tables (`orders_silver`)

---

### ğŸ¥‡ Gold Layer
- Enriched, business-ready fact-level order data (`orders_gold`)
- Dimensional modeling for BI and analytics use cases

### ğŸ§  Data Modeling Notes
- Fact table grain: one row per order line
- Surrogate keys used for all dimensions
- Dimensions implemented as SCD Type 1

**Star Schema (Power BI ready)**
- `dim_customers`
- `dim_products`
- `dim_geography`
- `dim_date`
- `fact_sales`

---

### ğŸ”„ Orchestration
- Databricks Workflows for end-to-end pipeline execution
- Idempotent Delta MERGE operations for incremental and repeatable loads
